{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov decision processes\n",
    "\n",
    "In the previous chapter with bandits, every time we made an action the environment did not change. In this chapter we will consider environments where the state of the world changes after we make an action. We will call these environments Markov decision processes (MDPs). We will also consider the problem of finding the best policy for an MDP, which is called the policy optimization problem.\n",
    "\n",
    "![](media/chapter-3/MDP-schema.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above figure shows the schema of a genral RL process: \n",
    "\n",
    "* An agent makes and action \n",
    "\n",
    "* The action perturbs the environment and the environment returns a reward and a new state\n",
    "\n",
    "* The agent uses the reward and the new state to update its policy\n",
    "\n",
    "* The cycle continues. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('rl-env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2cf5e1b4dfd04b667f9bceb775bba509c4b1aef371dee70d8088b9680fed7c5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
