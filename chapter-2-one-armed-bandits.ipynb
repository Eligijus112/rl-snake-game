{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One armed bandits \n",
    "\n",
    "The one armed bandit is a slang for the slot machines in casinos.\n",
    "\n",
    "![](media/chapter-2/one-armed-bandit.jpg)\n",
    "\n",
    "The action here is the pulling of the lewer. Each action costs a certain amount of money. The reward is unknown. If we have a fixed budget of money and we have multiple slot machines, we may want to have a strategy as to what machine to pull. If we spend all or our money on one slot machine, we can never know what is the average return of another. \n",
    "\n",
    "In practise, a common problem RL tries to solve is the so called k - armed bandit problem. The k - armed bandits simbolize the possible k actions that an agent can take \n",
    "having a fixed budget. \n",
    "\n",
    "# Explotation vs exploration \n",
    "\n",
    "One of the fundamental problems in reinforced learning is the explotation vs exploration part.  \n",
    "\n",
    "**Exploration** allows an agent to improve its current knowledge about each action, hopefully leading to long-term benefit. Improving the accuracy of the estimated action-values, enables an agent to make more informed decisions in the future.\n",
    "\n",
    "**Exploitation** on the other hand, chooses the greedy action to get the most reward by exploiting the agentâ€™s current action-value estimates. But by being greedy with respect to action-value estimates, and agent may not actually get the most reward and lead to sub-optimal behaviour. \n",
    "\n",
    "When an agent explores, it gets more accurate estimates of action-values. And when it exploits, it might get more reward. It cannot, however, choose to do both simultaneously, which is also called the `exploration-exploitation dilemma`.\n",
    "\n",
    "# A/B testing using RL algorithm \n",
    "\n",
    "In this section I will lay the groundwork for an A/B testing using Reinforcement Learning. \n",
    "\n",
    "The schema is the following: \n",
    "\n",
    "![](media/chapter-2/a_b_test.png)\n",
    "\n",
    "A user logs on to a website where a backend robot (our `agent`) introduces randomly either green or yellow buttons to click (`actions`). After clicking these buttons, the user then proceeds to the next page where he can shop around. The final value of a shopping carts is relayed back to the agent (`reward` from the `environment`). This information is digested by the agent and the agent stores this information. \n",
    "\n",
    "At the end of the experiment run, the agent can say the average spending by customers when clicked on the either green or yellow buttons. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "42188ee9869e2b119220b29afa41430f1e45d9b6ba28e06c978bb38ae44da5c8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('snake_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
